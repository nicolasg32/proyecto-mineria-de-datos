{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CC5205 - Minería de Datos  \n",
    "Prof. Felipe Bravo y Hernán Sarmiento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hito 3 - Equipo 11\n",
    "Vicente Guzmán - Ignacio Muñoz - Nicolás González - Javier Atenas - José Arriagada"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steam es la plataforma líder de distribución digital de videojuegos en PC, y este mercado cada vez tiene más consumidores y va ganando terreno por sobre otras formas de entretención.\n",
    "Esto lo demuestra su co-fundador Gabe Newell, el cual con su plataforma es uno de los 1000 hombres más ricos del mundo.\n",
    "Siendo este un mercado en constante cambio con millones de usuarios, vale la pena investigar sobre su contenido, junto a sus ascensos y caídas.\n",
    "Estudiar este dataset podría ayudar a entender las preferencias en el mercado de los videojuegos, cuáles son los más vendidos y cuáles tienen las mejores valoraciones, entre otros estudios."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de Datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este dataset posee datos de más de 27.000 juegos y algunos pocos softwares estrenados hasta el 2019 en formato CSV.\n",
    "Tiene datos como el nombre, la descripción, la categoría, el género, los logros de cada juego, la fecha de lanzamiento, el desarrollador, el *publisher*, la edad requerida para jugar el juego, la cantidad de gente que posee el juego, el precio, el promedio del tiempo de juego de los usuarios y la puntuación positivas y negativa de los usuarios.\n",
    "\n",
    "Tenemos que las columnas \"genre\", \"categories\", \"platforms\"  y \"steamspy_tags\", son de tipo string. Es decir, que son listas de elementos separados por punto y coma.(Ej: \"action\" es un género diferente a \"action;Indie\", a pesar de que a nuestro entendimiento, si son del mismo género).\n",
    "Por lo que si se quisiera revisar todos los juegos que sean del género \"action\", saldrían solamente aquellos juegos que tuviesen como único género \"action\".\n",
    "\n",
    "Para trabajar con los datos que consideramos relevantes, debimos convertir cada elemento de las columnas mencionadas anteriormente en una columna binaria. Esta nueva columna indica la presencia o ausencia del elemento: si el elemento específico está presente, se marca con un \"1\", y si no, se asigna un \"0\".\n",
    "\n",
    "Para entender de mejor manera cómo están distribuidos los datos del dataset, se deja el código fuente de la fase exploratoria en la sección de 'Código Fuente'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preguntas y Problemas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos un árbol de regresión lineal que nos ayuda a predecir el precio que tiene un juego en la tienda. para entrenar el modelo usamos el 80% de los datos para entrenar y el 20% restante para testear que tan bueno es el modelo prediciendo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el hito 1 se postularon las siguientes preguntas e hipótesis, que surgieron al hacer la fase exploratoria de los datos:\n",
    "\n",
    "-   ¿Cuáles son los géneros que generan más ingresos?\n",
    "\n",
    "-   ¿Qué géneros tienen un mejor porcentaje de reviews positivas?\n",
    "\n",
    "-   ¿Existe una relación entre el tiempo promedio de juego y sus reviews?  \n",
    "    Hipótesis: Hay una relación directa entre las reviews de un juego y tiempo de juego, ya que si un jugador no disfruta un juego y le escribe una mala review, tampoco querrá jugarlo, por lo tanto los juegos con altos tiempos de juego tendrán mejores reviews.\n",
    "\n",
    "-   ¿Qué relación hay entre el precio de un juego y su tiempo de juego promedio?  \n",
    "    Hipótesis: Hay una relación directa entre el precio de un juego y tiempo de juego, ya que los usuarios \"harán valer\" el dinero invertido, haciendo que jueguen un juego caro mucho más que uno gratis, para sentir que valió la pena.\n",
    "\n",
    "-   ¿Los juegos con más logros tienen más tiempo de juego que los juegos con menos logros?\n",
    "\n",
    "-   ¿Los *publishers* influyen en la cantidad de ventas de un juego?  \n",
    "    Hipótesis: Si, pues los *publishers* más conocidos harán que el juego se destaque más en el mercado, pues da el sello de garantía de que ellos lo aprobaron, y si la gente confía en ellos, confiarán en este nuevo juego.\n",
    "    Mientras que los *indies* tienen menos base de publicidad.\n",
    "\n",
    "\n",
    "Posterior a la corrección del primer hito, se observaron errores en el enfoque y preguntas realizadas. Esto se logró corregir, mejorando el primer análisis. De la fase exploratoria se pudo observar que las preguntas que se plantean pueden ser resueltas con los datos sin tener que realizar ningún procedimiento muy complejo y no se halló otros datasets que pudieran aportar mayor valor a la investigación. A continuación se enumeran las nuevas preguntas planteadas.\n",
    "\n",
    "1.    ¿Es posible predecir el precio del juego en función del Promedio de tiempo jugado, valoración y/o los tags que posea?\n",
    "  \n",
    "2.   ¿Existen grupos importantes de juegos que se comporten de manera similar en cuanto a precio de acuerdo a características del juego (promedio tiempo jugado, valoración) o  en cuanto al género o tags que posee? ¿Hay alguna relación entre estas?\n",
    "  \n",
    "3.   ¿Hay características específicas de los juegos que permitan tener mejor o peor valoración del público?\n",
    "  \n",
    "4.   ¿Sería posible conocer la valoración (aproximada) de un nuevo juego que entra al mercado considerando sus características?\n",
    "\n",
    "  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para examinar mejor los datos necesarios, se extraerán las columnas necesarias para analizar cada pregunta y así bajar la dimensionalidad.\n",
    "- Dado que las preguntas 1 y 4 son de carácter predictivo, el procedimiento se centrará en la clasificación, donde se propone utilizar el dataset que se posee, modificarlo, obtener un modelo que permita obtener la valoración de un juego y así estimar valoración, precio u otros a partir de un conjunto de otras características.\n",
    "- Para la pregunta 2, se aplicarán técnicas de clustering para encontrar si es que las características del dataset son suficientes para encontrar grupos de juegos similares a otros en características.\n",
    "- Se probarán múltiples valores en el número de clúster elegidos así como distintos enfoques de clustering. \n",
    "- Para esto se necesita dejar solo las columnas que contengan valores numéricos con datos trascendentes para cada pregunta. \n",
    "- Se experimentará con distintos subconjuntos de atributos al momento de hacer clustering y así evaluar si los datos se agrupan de manera distinta cuando se consideran características diferentes. \n",
    "- Para la pregunta 3, se realizarán matrices de correlación, se aplicarán modelos de predicción y se realizará una visualización de los 15 juegos con mejor y peor valoración, para ver si algunas características pueden afectar la valoración de un juego."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la pregunta \"¿Es posible predecir el precio del juego en función del Promedio de tiempo jugado, valoración y/o los tags que posea?\" se realizará primeramente una regresión lineal y posteriormente se usarán herramientas de clasificación para elegir la mejor opción siguiendo la siguiente clasificación\n",
    "##### Regresión Lineal\n",
    "- Lo primero es hacer una tabla con las columnas numéricas relevantes para entrenar un modelo que ayude a responder la pregunta.\n",
    "- Se hace un árbol de regresión lineal.\n",
    "- Se utiliza el árbol para ayudar a predecir el precio que tiene un juego en la tienda. Para entrenar el modelo se usa el 80% de los datos y el 20% restante se usa para testear qué tan bueno es el modelo.\n",
    "- Al correr varias veces el código del árbol de regresión lineal obtenemos un Mean Squared Error (MSE) o error cuadrático medio de aproximadamente 131, lo que se traduce a 11 dólares aproximadamente de error. Y considerando que el precio de los juegos varia entre 0 y 400 dólares podemos notar que el modelo tiene un buen ajuste y que las predicciones están en general cercanas a los valores reales. \n",
    "- Como resultado preliminar, creamos un juego con datos ficticios en todos los atributos pero sin precio, y el modelo supone su precio, el cual tomando en cuenta el error variara en máximo 10 dólares\n",
    "##### Discretización\n",
    "Antes de trabajar con clasificación se realizará una discretización de los precios.\n",
    "- se usará la función cut de pandas y se agregará una columna \"intervaloprecio\" que contará el intérvalo de precios en dólares en que está que irá de 0 a 10, de 10 a 20, de 20 a 30, de 30 a 40, de 40 a 50 y mayores que 50.\n",
    "- luego se hará una tabla x con todos los valores numéricos menos el precio y una tabla y con la columna \"intervaloprecio\".\n",
    "\n",
    "##### Clasificación\n",
    "- Se creara un árbol de clasificación\n",
    "- Se dividirá x e y con train_test_split con el 30% de testing\n",
    "- Luego se entrenara el árbol con el 70% de los datos\n",
    "- Después se calculará la precisión, recall y f1-score del árbol con un classification report.\n",
    "- Graficaremos una matriz de confusión para sus test.\n",
    "- Volveremos a analizar, esta vez con validación cruzada.\n",
    "- Finalmente repetiremos los pasos con oversampling y undersampling.\n",
    "\n",
    "En los intervalos más bajos, todos los valores de todas las pruebas estuvieron similares aproximadamente en 80% , sin embargo en los intervalos más altos se notó una superioridad de el testing con oversampling, por ejemplo en los juegos de entre 40 y 50 dólares, y los que costaban más de 50 dólares, el testing en la muestra sin modificar y en la que tiene subsampling aciertan aproximadamente un 10% de las veces, mientras en el árbol que se entrenó con oversampling los aciertos son de aproximadamente el 90%.\n",
    "Con lo cuál si es posible acercarse bastante al rango de precios de un juego si tomamos atributos como las características o género."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizarán los siguientes pasos para resolver la pregunta 2: \"¿Existen grupos importantes de juegos que se comporten de manera similar en cuanto a precio de acuerdo a características del juego (como por ejemplo promedio tiempo jugado, valoración) o en cuanto al género o tags que posee?¿Hay alguna relación entre estas?\":\n",
    "\n",
    "- Hallar los clusters óptimos a utilizar para el análisis, mediante el método del codo, o en caso contrario de no ser de mucha ayuda, usar puntaje de silueta.\n",
    "- Se grafica según el numero de clusters elegidos mediante PCA, y se verifica si los clusters elegidos sirven para su análisis o hay que escoger otro numero.\n",
    "- Se analizan estos clusters según sus medias, para ayudar a tener una idea de las características mediante las cuales los juegos fueron agrupados en estos clusters y además de relacionar el precio con cada uno.\n",
    "- Observar algunos juegos pertenecientes a cada cluster y asi analizar alguna posible relación, para explicar el por que fueron agrupados dentro del mismo cluster.\n",
    "\n",
    "Gracias a realizar estos pasos, se obtuvo un numero de clusters optimos para el analisis igual a 4, esto gracias al puntaje de silueta y analizar que 5 clusters dejaba un cluster solo para un juego, lo cual era algo redundante. Además se obtuvieron resultados interesantes de analizar, como los relatados a continuación.\n",
    "\n",
    "\n",
    "Se obtiene que la relación que presentan los juegos dentro de estos clusters es la siguiente:\n",
    "\n",
    "- cluster 0: Son juegos singleplayers que en su mayoría poseen una campaña (como sería el caso de half-life).\n",
    "\n",
    "- cluster 1: Son juegos con tags indie y/o metroidvania (como ejemplo, el guacamelee ).\n",
    "\n",
    "- cluster 2: Son juegos de acción en su mayoría multiplayer (tales como counter strike, team fortress o ricochet). \n",
    "\n",
    "- cluster 3: Son juegos o softwares que presentan utilidades para el usuario, tales como desarrollo de videojuegos o elementos audiovisuales, modelamiento 3d y demases ( un ejemplo sería Axis Game Factory's AGFPRO v3).\n",
    "\n",
    "Se puede verificar estas relaciones en base al analisis de los clusters:\n",
    "\n",
    "- El precio aproximado de los singleplayers es de 6 dolares (dato que podria aprobarse puesto que al ser tantos juegos la mayoria deben ser muy baratos), el precio aproximado de indies es 10 dolares (al no ser muchos, suelen generar cierta espectativa en el mercado, juegos como Project Zomboid valen 10 dolares), los multiplayers cerca de 8 dolares(precio que se podria aceptar pues muchos juegos como FIFA salen por cerca de 50 dolares y muchos como Counter Strike Global Offensive son gratis), y por ultimo los juegos o softwares de utilidad valen en promedio 27 dolares (Precio bastante promedio, teniendo en cuenta que los juegos mas caros (500 dolares aprox) de Steam son softwares de desarrollo de videojuegos).\n",
    "\n",
    "- La relacion entre valoraciones positivas y negativas de los singleplayers es de 6 a 1 aproximadamente, con lo cual quiere decir que son medianamente aceptados, pues tener 60 positivas y 10 negativas no es tan bueno. Por otro lado los indies suelen ser menos criticados que los singleplayers con una impresionante relacion de 20 a 1, podria explicarse ya que al ser juegos con no mucha expectativa suelen sorprender bastante. El caso de los multiplayers es el peor, ya que al haber competitividad se explica su relacion de 4 a 1, la gente enfurece y critica el juego. En el ultimo cluster de softwares de utilidad, les suele ir muy bien pues complacen al usuario al lograr realizar la funcion de estos, con un 16 a 1 de relación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la pregunta \"¿Hay características específicas de los juegos que permitan tener mejor o peor valoración del público?\" y ver si es que hay características específicas de los juegos que afecten a la valoración, se realizaran los siguientes pasos:\n",
    "- Primero se realizará una matriz de correlación de Pearson entre las características. \n",
    "- Luego, se aplicará un modelo de predicción de regresión lineal, con el fin de revisar como se ven afectados las \"positive_rating\" y los \"negative_rating\". \n",
    "- Por último, se grafica y se comparan los 15 juegos con más valoraciones positivas con los juegos con más valoraciones negativas. \n",
    "\n",
    "Con los pasos realizados, se obtuvieron valores en la matriz de correlación, con lo cuales se puede ver que en ambas valoraciones la mayoría de características tienen valores cercanos al 0, a excepción del valor que hay entre las valoraciones positivas y las valoraciones negativas, el cual es 0.762804. Esto significa que ninguna de las otras características, según la matriz de correlación de Pearson, afecta de manera significativa, solo las valoraciones positivas influyen en las valoraciones negativas y viceversa.\n",
    "\n",
    "De los modelos de predicción, con el modelo de predicción de regresión lineal resultó que para las valoraciones positivas, el coeficiente de determinación R^2 es de valor -8.398122088462335, en donde el valor tiene que ser entre 0 y 1, entonces este modelo es extremadamente malo. Por otro lado, para las valoraciones negativas, el valor del coeficiente de determinación R^2 tiene un valor de 0.2897987891716105, el cual al ya estar entre 0 y 1, el modelo es útil comparado con el modelo de las valoraciones positivas. Los coeficientes de regresión resultantes indican que los logros y la mediana del tiempo jugado son inversos a las valoraciones negativas, mientras que el resto de características tienen una relación directa con la valoración negativa. Esto se puede interpretar como que mientras menos logros y la mediana del tiempo jugado sea menor, las valoraciones negativas serán mayores.\n",
    "\n",
    "En la parte de los gráficos donde se encuentran los 15 juegos con mayor cantidad de valoraciones positivas y los 15 juegos con mayor cantidad de valoraciones negativas, hay varias cosas interesantes. Por ejemplo, se ve que el juego \"Counter-Strike: Global Offensive\" es el que tiene el valor más alto de \"positive_rating\" con mucha diferencia y que \"PLAYERUNKWON'S BATTLEGROUND\" es el que tiene el valor más alto de \"negative_ratings\", pero siendo \"Counter-Strike: Global Offensive\" el segundo juego con mayor cantidad de valoraciones negativas, ambos juegos con una gran diferencia con respecto a los otros juegos dentro del top 15. Otros juegos, junto a los dos ya mencionados, se repiten en ambos top 15, como por ejemplo: \"Dota 2\", \"Grand Theft Auto 5\", \"Garrys'mod\", \"PAYDAY 2\" y \"RUST\". Los resultados del análisis de regresión lineal, se ve reflejado en los gráficos hechos, en donde varios juegos están en los top 15 con mayor cantidad de valoraciones negativas y positivas.\n",
    "\n",
    "Todo el código utilizado se encuentra en la sección del Anexo en código fuente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la pregunta *'¿Sería posible conocer la valoración (aproximada) de un nuevo juego que entra al mercado considerando sus características?'* se van a utilizar diversas técnicas tanto de regresión como de clasificación, para abordar esta pregunta desde distintos modelos y ver si hay alguno que funcione mejor.\n",
    "Lo primero que se hace es crear una nueva columna que contenga el porcentaje de valoraciones positivas en números enteros para poder visualizar de mejor manera la variable objetivo, pues interesa más juntar las columnas de `positive_ratings` y `negative_ratings` que analizarlas por separado, y luego se sacan los juegos que no tengan valoraciones, ya que no aportan a los modelos predictivos. De la misma manera, se limpia el dataframe de las columnas con datos intrascendentes para lo juegos nuevos, como lo son las columnas de valoraciones o de tiempo jugado, pues no aplican.\n",
    "\n",
    "Con estas cosas listas, se procede a definir la variable objetivo como la columna que contiene el porcentaje de valoraciones positivas y se genera un árbol de decisión que se entrena con dos tercios de los datos y se prueba con los demás datos. Se hace una prueba de precisión y da como resultado un valor aproximado de 0.05, siendo este un pésimo indicador, dado que mientras más cercano el valor a cero, menos aciertos hace el modelo, por lo que no se puede fiar mucho de este modelo. Aún así, se procede a ver cuáles son los atributos más importantes del árbol para hacer una idea de cuáles son los valores que más aportan a la predicción. Los atributos más relevantes de este modelo son el precio del juego con un valor de 0.15 y la cantidad de logros con un 0.13, que si bien tienen valores muy bajos, son los que más resaltan en comparación con los demás, que tienen un valor bajo 0.04, por lo que se vuelven insignificantes. \n",
    "\n",
    "Ahora, se realiza un modelo de regresión lineal con los mismos datos de entrenamiento y se evalúa a partir de los valores MSE, R2 y validación cruzada y se obtienen los siguientes datos:\n",
    "- MSE: 979.37\n",
    "- R-squared: -0.769\n",
    "- Cross-Validated MSE: 4.813264893236852e+18\n",
    "- Cross-Validated R-squared: -1.3243866615940194e+16\n",
    "\n",
    "Gracias al MSE vemos que este modelo tiene un error gigante, lo mismo podemos concluir con su validación cruzada. Con el R2 vemos que este modelo no se ajusta bien a los datos pues los valores de R2 van de 0 a 1, y valores negativos indican que no es capaz de explicar la variabilidad de la variable objetivo, y lo mismo vemos con su validación cruzada, que también es negativa.\n",
    "\n",
    "Finalmente, se aplica una regresión con Random Forest con los mismos datos de entrenamiento y se evalúa con los valores de MSE, R2 y validación cruzada, igual que con el modelo anterior y se obtienen los siguientes datos:\n",
    "\n",
    "- MSE: 524.86\n",
    "- R-squared: 0.051\n",
    "- Cross-Validated MSE: 541.77\n",
    "- Cross-Validated R-squared: 0.005\n",
    "\n",
    "Se ve que este modelo trabaja mejor los datos que el modelo anterior, pero el MSE sigue indicando que el modelo tiene un error inmenso, el R2 indica que solo pudo explicar el 5% de la variabilidad de valoraciones, y la valoración cruzada indica que el modelo no generaliza bien a nuevos datos y es poco confiable, por lo que tampoco sirve mucho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobre la pregunta 1, si bien predecir el precio exacto puede ser muy complicado, utilizando herramientas de discretización y clasificando por rangos es posible predecir el rango de precios en el que fluctuará un juego según sus valoraciones, promedio de tiempo de juego y sus características o géneros.\n",
    "\n",
    "Con respecto a la pregunta 2, donde se preguntaba por una posible agrupación de los juegos para hallar patrones de precio en cuanto a sus características, se pudo concluir que utilizando las herramientas enseñadas en clase (clustering) se logró agruparlos y hallarle sentido a estas agrupaciones. Con estos resultados ademas se logró un análisis de estas agrupaciones y tener ciertas ideas acerca de las características que presentan estas, ya sea genero, tags, valoraciones, precio, entre otras. \n",
    "\n",
    "Para la pregunta 3, se concluye que no es posible determinar si hay características que afecten a las valoraciones de los juegos, a través de la utilización de matrices de correlación de Pearson, modelos de regresión de lineal y gráficos, debido a que según los resultados obtenidos indican que las valoraciones positivas solo se ven afectadas por las negativas y viceversa.\n",
    "\n",
    "Con respecto a la pregunta de si es posible predecir la valoración de un nuevo juego, se puede concluir que es muy difícil, por no decir imposible, pues ninguno de los modelos utilizados para predecir esta incógnita lanzó un resultado confiable, e incluso en algunos casos el modelo ni siquiera pudo ajustarse bien a los datos. A pesar de esto, se puede determinar que el precio y la cantidad de logros pueden tener un rol importante de cara a predecir la valoración del nuevo juego, aunque sigue siendo poco confiable este resultado.\n",
    "\n",
    "En conclusión, este trabajo ha sido un éxito rotundo gracias a la dedicación y trabajo en equipo. Hemos logrado alcanzar parte de nuestros objetivos y plantear posibles nuevas preguntas, lo que nos llena de satisfacción.\n",
    "\n",
    "Durante el desarrollo del proyecto, hemos enfrentado diversos desafíos que han puesto a prueba nuestra capacidad de planteamiento y resolución de problemas. Sin embargo, hemos demostrado una gran capacidad para enfrentar estos retos de manera creativa y efectiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planificación Futura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tratar de predecir un precio surge la duda de cuáles serán los \"tags\" de Steam más críticos para un valor, por lo tanto a futuro podría hacerse un análisis para elegir de los casi 400 tags que tiene los mas importantes.\n",
    "\n",
    "Al generar agrupaciones de juegos en la pregunta 2, nos surgen nuevas preguntas acerca de comparar mas características con respecto a estas agrupaciones, por ejemplo ver posibles nuevas agrupaciones dentro de cada una de estas agrupaciones y así continuar desglosando mas aun los precios de cada una de estas nuevas agrupaciones, y también la idea de seguir modificando la tabla para hallar mas patrones.\n",
    "\n",
    "Con respecto al estudio de los juegos nuevos, gusta la idea de poder introducir a la ecuación los desarrolladores del juego y las publicadoras, puesto que estos valores indican qué tan confiable es el juego para la opinión popular, e incluso sirve para ver cómo les va a los juegos indies con respecto a los hechos por empresas grandes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribuciones de cada miembro del equipo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vicente Guzmán estuvo a cargo del experimento 4, haciendo la ejecución y la redacción respectiva del informe y contribuyendo a las propuestas a futuro.\n",
    "\n",
    "Ignacio Muñoz trabajo en limpiar el dataset para poder ser utilizado en cada uno de los experimentos, aportando también a la redacción del informe.\n",
    "\n",
    "Nicolás González Trabajó en mejorar fallos del hito 1 y en la propuesta experimental general de las preguntas. Para el hito 3 se encargó de buscar respuestas para el planteamiento de la pregunta 2 y contribuir a las propuestas a futuro.\n",
    "\n",
    "Javier Atenas trabajó en el experimento 3, ayudo a al redacción del informe y aportó a la conclusión.\n",
    "\n",
    "José Arriagada estuvo a cargo del experimento 1, haciendo la ejecución y su redacción respectiva del informe, contando parte del desarrollo, conclusión y planificación a futuro. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código Fuente"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración de datos\n",
    "\n",
    "Se detalla el código utilizado para la exploración de datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código para acceder al dataset local y definirlo como X, mostrando los primeros elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Cambiar el directorio de trabajo a db\n",
    "wd = os.path.abspath(os.path.join(os.getcwd(), os.pardir, \"db\"))\n",
    "os.chdir(wd)\n",
    "\n",
    "steam = pd.read_csv(\"steam.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad de juegos que hay en la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(steam.name.nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad de desarrolladores que hay en la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(steam.developer.nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad de *publishers* que hay en la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(steam.publisher.nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico con las fechas de lanzamiento de los juegos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "steam['release_date'] = pd.to_datetime(steam['release_date'])\n",
    "steam['year'] = steam['release_date'].dt.year.astype(int)\n",
    "\n",
    "# Calcular el recuento de títulos por año\n",
    "title_counts = steam['year'].value_counts().sort_index()\n",
    "\n",
    "# Crear el gráfico de barras\n",
    "plt.bar(title_counts.index, title_counts.values)\n",
    "\n",
    "# Establecer títulos y etiquetas de los ejes\n",
    "plt.title(\"Títulos por año\")\n",
    "plt.xlabel(\"Año\")\n",
    "plt.ylabel(\"N° de títulos\")\n",
    "\n",
    "\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juegos que tienen uno o mas géneros en específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam2 = steam[steam['genres'].str.contains('Action')]\n",
    "steam3 = steam[steam['genres'].str.contains('Strategy') & steam['genres'].str.contains('RPG')]\n",
    "steam2.head()\n",
    "steam3.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juegos que poseen algún género en especíifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam4 = steam[steam['genres'].str.contains('Strategy|Action')]\n",
    "steam4.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juegos que no poseen alguno o mas géneros en específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam5 = steam[~steam['genres'].str.contains('Action')]\n",
    "steam6 = steam[~steam['genres'].str.contains('Strategy|Action')]\n",
    "steam5.head()\n",
    "steam6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico de top 10 juegos por cantidad de votos positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ordenamos el DataFrame por la columna 'positive_ratings' en orden descendente\n",
    "df_sorted = steam.sort_values('positive_ratings', ascending=False)\n",
    "\n",
    "# Seleccionamos las primeras 10 filas\n",
    "top_10_games = df_sorted.head(10)\n",
    "\n",
    "# Creamos el gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_10_games['name'], top_10_games['positive_ratings'])\n",
    "plt.title('Top 10 Juegos por Cantidad de Votos Positivos')\n",
    "plt.xlabel('Votos Positivos')\n",
    "plt.ylabel('Nombre del Juego')\n",
    "\n",
    "# Invertimos el eje y para que el juego con más votos aparezca en la parte superior\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad de juegos por género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Contamos la cantidad de juegos por género\n",
    "genre_counts = steam['genres'].str.split(';').explode().value_counts()\n",
    "\n",
    "# Creamos el gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "genre_counts.plot(kind='barh')\n",
    "plt.title('Cantidad de Juegos por Género')\n",
    "plt.ylabel('Género')\n",
    "plt.xlabel('Cantidad de Juegos')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para transformar las columnas de strings en columnas binarias realizamos lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dividimos las categorías y los géneros, y los apilamos para hacer un conteo cruzado\n",
    "categories = steam['categories'].str.split(';', expand=True).stack().reset_index(level=1, drop=True).to_frame('categories')\n",
    "genres = steam['genres'].str.split(';', expand=True).stack().reset_index(level=1, drop=True).to_frame('genres')\n",
    "steamspy_tags = steam['steamspy_tags'].str.split(';', expand=True).stack().reset_index(level=1, drop=True).to_frame('steamspy_tags')\n",
    "platforms = steam['platforms'].str.split(';', expand=True).stack().reset_index(level=1, drop=True).to_frame('platforms')\n",
    "\n",
    "# Hacemos un conteo cruzado para obtener las columnas binarias\n",
    "categories_binary = pd.get_dummies(categories, columns=['categories'], prefix='', prefix_sep='').groupby(level=0).sum()\n",
    "genres_binary = pd.get_dummies(genres, columns=['genres'], prefix='', prefix_sep='').groupby(level=0).sum()\n",
    "steamspy_tags = pd.get_dummies(steamspy_tags, columns=['steamspy_tags'], prefix='', prefix_sep='').groupby(level=0).sum()\n",
    "platforms_binary = pd.get_dummies(platforms, columns=['platforms'], prefix='', prefix_sep='').groupby(level=0).sum()\n",
    "\n",
    "\n",
    "# Unimos el dataframe original con las nuevas columnas de categorías y géneros\n",
    "steam = pd.concat([steam, categories_binary, genres_binary, steamspy_tags], axis=1)\n",
    "\n",
    "steam = steam.drop(columns=['categories', 'genres', 'steamspy_tags', 'platforms'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 1\n",
    "Se detalla el código utilizado para el experimento preliminar que intenta contestar la pregunta 1 estipulada para este hito."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla con las columnas numéricas relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las características numéricas\n",
    "features = ['appid' , 'english' , 'required_age' , 'achievements' ,\n",
    "            'positive_ratings' , 'negative_ratings' , 'average_playtime' ,\n",
    "            'median_playtime' , 'price' , 'Captions available' ,\n",
    "            'Co-op' , 'Commentary available' , 'Cross-Platform Multiplayer' ,\n",
    "            'Full controller support' , 'In-App Purchases' ,\n",
    "            'Includes Source SDK' , 'Includes level editor' , 'Local Co-op' ,\n",
    "            'Local Multi-Player' , 'MMO' , 'Mods' , 'Mods (require HL2)' ,\n",
    "            'Multi-player' , 'Online Co-op' , 'Online Multi-Player' ,\n",
    "            'Partial Controller Support' , 'Shared/Split Screen' ,\n",
    "            'Single-player' , 'Stats' , 'Steam Achievements' , 'Steam Cloud' ,\n",
    "            'Steam Leaderboards' , 'Steam Trading Cards' ,\n",
    "            'Steam Turn Notifications' , 'Steam Workshop' ,\n",
    "            'SteamVR Collectibles' , 'VR Support' , 'Valve Anti-Cheat enabled' ,\n",
    "            'Accounting' , 'Action' , 'Adventure' , 'Animation & Modeling' ,\n",
    "            'Audio Production' , 'Casual' , 'Design & Illustration' ,\n",
    "            'Documentary' , 'Early Access' , 'Education' , 'Free to Play' ,\n",
    "            'Game Development' , 'Gore' , 'Indie' , 'Massively Multiplayer' ,\n",
    "            'Nudity' , 'Photo Editing' , 'RPG' , 'Racing' , 'Sexual Content' ,\n",
    "            'Simulation' , 'Software Training' , 'Sports' , 'Strategy' ,\n",
    "            'Tutorial' , 'Utilities' , 'Video Production' , 'Violent' ,\n",
    "            'Web Publishing' , '1980s' , \"1990's\" , '2.5D' , '2D' , '2D Fighter' ,\n",
    "            '360 Video' , '3D' , '3D Platformer' , '3D Vision' , '4 Player Local' ,\n",
    "            '4X' , '6DOF' , 'Abstract' , 'Action' , 'Action RPG' , 'Action-Adventure' ,\n",
    "            'Adventure' , 'Agriculture' , 'Aliens' , 'Alternate History' , 'America' ,\n",
    "            'Animation & Modeling' , 'Anime' , 'Arcade' , 'Arena Shooter' , 'Assassin' ,\n",
    "            'Atmospheric' , 'Audio Production' , 'BMX' , 'Base-Building' , 'Baseball' ,\n",
    "            'Basketball' , 'Batman' , 'Battle Royale' , \"Beat 'em up\" , 'Beautiful' ,\n",
    "            'Benchmark' , 'Bikes' , 'Blood' , 'Board Game' , 'Bowling' , 'Building' ,\n",
    "            'Bullet Hell' , 'Bullet Time' , 'CRPG' , 'Capitalism' , 'Card Game' , 'Cartoon' ,\n",
    "            'Cartoony' , 'Casual' , 'Cats' , 'Character Action Game' , 'Character Customization' ,\n",
    "            'Chess' , 'Choices Matter' , 'Choose Your Own Adventure' , 'Cinematic' ,\n",
    "            'City Builder' , 'Class-Based' , 'Classic' , 'Clicker' , 'Co-op' , 'Cold War',\n",
    "            'Colorful' , 'Comedy' , 'Comic Book' , 'Competitive' , 'Controller' ,\n",
    "            'Conversation' , 'Crafting' , 'Crime' , 'Cult Classic' , 'Cute' , 'Cyberpunk' ,\n",
    "            'Cycling' , 'Dark' , 'Dark Fantasy' , 'Dark Humor' , 'Dating Sim' , 'Demons' ,\n",
    "            'Design & Illustration' , 'Destruction' , 'Detective' , 'Difficult' , 'Dinosaurs' ,\n",
    "            'Diplomacy' , 'Documentary' , 'Dog' , 'Dragons' , 'Drama' , 'Driving' , 'Dungeon Crawler' ,\n",
    "            'Dungeons & Dragons' , 'Dystopian ' , 'Early Access' , 'Economy' , 'Education' , 'Epic' , 'Experimental' ,\n",
    "            'Exploration' , 'FMV' , 'FPS' , 'Faith' , 'Family Friendly' , 'Fantasy' , 'Fast-Paced' , 'Female Protagonist' ,\n",
    "            'Fighting' , 'First-Person' , 'Fishing' , 'Flight' , 'Football' , 'Free to Play' , 'Funny' , 'Futuristic' ,\n",
    "            'Gambling' , 'Game Development' , 'GameMaker' , 'Games Workshop' , 'God Game' , 'Golf' , 'Gore' , 'Gothic' ,\n",
    "            'Grand Strategy' , 'Great Soundtrack' , 'Grid-Based Movement' , 'Gun Customization' , 'Hack and Slash' ,\n",
    "            'Hacking' , 'Hand-drawn' , 'Heist' , 'Hex Grid' , 'Hidden Object' , 'Historical' , 'Hockey' , 'Horror' ,\n",
    "            'Horses' , 'Hunting' , 'Illuminati' , 'Indie' , 'Intentionally Awkward Controls' , 'Interactive Fiction' ,\n",
    "            'Inventory Management' , 'Investigation' , 'Isometric' , 'JRPG' , 'Kickstarter' , 'LEGO' , 'Lara Croft' ,\n",
    "            'Lemmings' , 'Level Editor' , 'Linear' , 'Local Co-Op' , 'Local Multiplayer' , 'Logic' , 'Loot' , 'Lovecraftian' ,\n",
    "            'MMORPG' , 'MOBA' , 'Magic' , 'Management' , 'Mars' , 'Martial Arts' , 'Massively Multiplayer' , 'Masterpiece' ,\n",
    "            'Match 3' , 'Mature' , 'Mechs' , 'Medieval' , 'Memes' , 'Metroidvania' , 'Military' , 'Mini Golf' , 'Minimalist' ,\n",
    "            'Mining' , 'Mod' , 'Moddable' , 'Motocross' , 'Motorbike' , 'Mouse only' , 'Movie' , 'Multiplayer' , 'Multiple Endings' ,\n",
    "            'Music' , 'Music-Based Procedural Generation' , 'Mystery' , 'Mystery Dungeon' , 'Mythology' , 'NSFW' , 'Narration' , 'Naval' ,\n",
    "            'Ninja' , 'Noir' , 'Nonlinear' , 'Nudity' , 'Offroad' , 'Old School' , 'On-Rails Shooter' , 'Online Co-Op' , 'Open World' ,\n",
    "            'Otome' , 'Parkour' , 'Parody ' , 'Party-Based RPG' , 'Perma Death' , 'Philisophical' , 'Photo Editing' , 'Physics' ,\n",
    "            'Pinball' , 'Pirates' , 'Pixel Graphics' , 'Platformer' , 'Point & Click' , 'Political' , 'Politics' , 'Pool' ,\n",
    "            'Post-apocalyptic' , 'Procedural Generation' , 'Programming' , 'Psychedelic' , 'Psychological' , 'Psychological Horror' ,\n",
    "            'Puzzle' , 'Puzzle-Platformer' , 'PvP' , 'Quick-Time Events' , 'RPG' , 'RPGMaker' , 'RTS' , 'Racing' , 'Real Time Tactics' ,\n",
    "            'Real-Time' , 'Real-Time with Pause' , 'Realistic' , 'Relaxing' , 'Remake' , 'Replay Value' , 'Resource Management' , 'Retro' ,\n",
    "            'Rhythm' , 'Robots' , 'Rogue-like' , 'Rogue-lite' , 'Romance' , 'Rome' , 'Runner' , 'Sailing' , 'Sandbox' , 'Satire' ,\n",
    "            'Sci-fi' , 'Science' , 'Score Attack' , 'Sexual Content' , \"Shoot 'Em Up\" , 'Shooter' , 'Short' , 'Side Scroller' ,\n",
    "            'Simulation' , 'Singleplayer' , 'Skateboarding' , 'Skating' , 'Sniper' , 'Snow' , 'Snowboarding' , 'Soccer' , 'Software' ,\n",
    "            'Software Training' , 'Sokoban' , 'Souls-like' , 'Space' , 'Space Sim' , 'Spectacle fighter' , 'Spelling' , 'Split Screen' ,\n",
    "            'Sports' , 'Star Wars' , 'Stealth' , 'Steampunk' , 'Story Rich' , 'Strategy' , 'Strategy RPG' , 'Stylized' , 'Submarine' ,\n",
    "            'Superhero' , 'Supernatural' , 'Surreal' , 'Survival' , 'Survival Horror' , 'Swordplay' , 'Tactical' , 'Tactical RPG' ,\n",
    "            'Tanks' , 'Team-Based' , 'Tennis' , 'Text-Based' , 'Third Person' , 'Third-Person Shooter' , 'Thriller' , 'Time Attack' ,\n",
    "            'Time Management' , 'Time Manipulation' , 'Time Travel' , 'Top-Down' , 'Top-Down Shooter' , 'Touch-Friendly' , 'Tower Defense' ,\n",
    "            'Trading' , 'Trading Card Game' , 'Trains' , 'Turn-Based' , 'Turn-Based Combat' , 'Turn-Based Strategy' , 'Turn-Based Tactics' ,\n",
    "            'Twin Stick Shooter' , 'Typing' , 'Underwater' , 'Utilities' , 'VR' , 'VR Only' , 'Vampire' , 'Video Production' ,\n",
    "            'Villain Protagonist' , 'Violent' , 'Visual Novel' , 'Voice Control' , 'Voxel' , 'Walking Simulator' , 'War' , 'Wargame' ,\n",
    "            'Warhammer 40K' , 'Web Publishing' , 'Werewolves' , 'Western' , 'Word Game' , 'World War I' , 'World War II' , 'Wrestling' ,\n",
    "            'Zombies' , 'e-sports']\n",
    "\n",
    "columnas_numericas = (\"english\", \"required_age\", \"achievements\", \"positive_ratings\", \"negative_ratings\", \"average_playtime\", \"median_playtime\", \"price\")\n",
    "X = steam[list(columnas_numericas)] \n",
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Árbol de regresión lineal con el 80% de los datos para entrenar y el 20% restante para testear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "x1= steam[list(features)] \n",
    "clf = DecisionTreeRegressor()\n",
    "y = x1.price\n",
    "Xwp = x1.copy()\n",
    "Xwp = Xwp.drop(\"price\", axis=1)\n",
    "clf.fit(Xwp, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xwp, y, test_size=0.2, random_state=42)\n",
    "\n",
    "regressor = DecisionTreeRegressor()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juego ficticio con valores ficticios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "lista_numeros = [random.randint(0, 1) for _ in range(398)]\n",
    "# Valores de ejemplo para los otros atributos\n",
    "english = 1\n",
    "required_age = 18\n",
    "achievements = 50\n",
    "positive_ratings = 1000\n",
    "negative_ratings = 200\n",
    "average_playtime = 120\n",
    "median_playtime = 90\n",
    "\n",
    "# Preparar los valores de los atributos para la predicción\n",
    "input_data = [english, required_age, achievements, positive_ratings, negative_ratings, average_playtime, median_playtime]\n",
    "input_data = [input_data + lista_numeros]\n",
    "# Realizar la predicción\n",
    "predicted_price = regressor.predict(input_data)\n",
    "\n",
    "# Imprimir el valor predicho\n",
    "print(\"Predicted Price:\", predicted_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretizaremos para pasar a clasificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=steam[list(features)].copy()\n",
    "intervals = [-1,10,20,30,40,50,float('inf')]\n",
    "labels = ['0-10', '10-20', '20-30', '30-40','40-50','>50']\n",
    "\n",
    "df['intervaloprecio'] = pd.cut(df['price'], bins=intervals, labels=labels)\n",
    "y=df.intervaloprecio\n",
    "dfwp = df.copy()\n",
    "dfwp = dfwp.drop(\"intervaloprecio\", axis=1)\n",
    "dfwp = dfwp.drop(\"price\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el árbol de decisión y observamos métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfwp, y, test_size=.3, random_state=1,\n",
    "                                                    stratify=y)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos matriz de confusión asociada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "classes = unique_labels(y_test, y_pred)\n",
    "\n",
    "df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "\n",
    "g = sns.heatmap(df, annot=True, cmap=\"Blues\")\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation=0)\n",
    "\n",
    "plt.title('Confusion matrix \\n')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "plt.autoscale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos Cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', 'accuracy', 'f1_macro']\n",
    "cv_results = cross_validate(\n",
    "    clf, dfwp, y, cv=10, scoring=scoring, return_train_score=True)\n",
    "\n",
    "print('Promedio Precision:', np.mean(cv_results['test_precision_macro']))\n",
    "print('Promedio Recall:', np.mean(cv_results['test_recall_macro']))\n",
    "print('Promedio F1-score:', np.mean(cv_results['test_f1_macro']))\n",
    "print('Promedio Accucary:', np.mean(cv_results['test_accuracy']))\n",
    "\n",
    "print('Promedio Precision k-fold:', cv_results['test_precision_macro'])\n",
    "print('Promedio Recall k-fold:', cv_results['test_recall_macro'])\n",
    "print('Promedio F1-score k-fold:', cv_results['test_f1_macro'])\n",
    "print('Promedio Accucary k-fold:', cv_results['test_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las muestras con over y undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "overdf = steam[list(columnas_numericas)].copy()\n",
    "overdf['intervaloprecio'] = pd.cut(overdf['price'], bins=intervals, labels=labels)\n",
    "overDfY = overdf['intervaloprecio']\n",
    "overDfX = overdf[list(columnas_numericas)]\n",
    "overDfX = overDfX.drop(\"price\", axis=1)\n",
    "smote = SMOTE()\n",
    "X_smote, Y_smote = smote.fit_resample(overDfX, overDfY)\n",
    "\n",
    "tomek = TomekLinks()\n",
    "X_tomek, y_tomek = tomek.fit_resample(overDfX, overDfY)\n",
    "print(\"Tamaño del conjunto de datos original:\")\n",
    "print(overDfY.value_counts())\n",
    "\n",
    "print(\"\\nTamaño del conjunto de datos después del sobremuestreo (SMOTE):\")\n",
    "print(Y_smote.value_counts())\n",
    "print(\"\\nTamaño del conjunto de datos después del submuestreo (Tomek Links):\")\n",
    "print(y_tomek.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos lo mismo que en la muestra normal con oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sobretrain, X_sobretest, y_sobretrain, y_sobretest = train_test_split(X_smote, Y_smote, test_size=.3, random_state=1,\n",
    "                                                    stratify=Y_smote)\n",
    "clfO = DecisionTreeClassifier()\n",
    "clfO.fit(X_sobretrain, y_sobretrain)\n",
    "y_sobrepred = clfO.predict(X_sobretest)\n",
    "print(\"Accuracy:\", accuracy_score(y_sobretest, y_sobrepred))\n",
    "print(classification_report(y_sobretest, y_sobrepred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmO = confusion_matrix(y_sobretest, y_sobrepred)\n",
    "\n",
    "classes = unique_labels(y_sobretest, y_sobrepred)\n",
    "\n",
    "dfO = pd.DataFrame(cmO, index=classes, columns=classes)\n",
    "\n",
    "g = sns.heatmap(dfO, annot=True, cmap=\"Blues\")\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation=0)\n",
    "\n",
    "plt.title('Confusion matrix \\n')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "plt.autoscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "    clfO, X_smote, Y_smote, cv=10, scoring=scoring, return_train_score=True)\n",
    "\n",
    "print('Promedio Precision:', np.mean(cv_results['test_precision_macro']))\n",
    "print('Promedio Recall:', np.mean(cv_results['test_recall_macro']))\n",
    "print('Promedio F1-score:', np.mean(cv_results['test_f1_macro']))\n",
    "print('Promedio Accucary:', np.mean(cv_results['test_accuracy']))\n",
    "\n",
    "print('Promedio Precision k-fold:', cv_results['test_precision_macro'])\n",
    "print('Promedio Recall k-fold:', cv_results['test_recall_macro'])\n",
    "print('Promedio F1-score k-fold:', cv_results['test_f1_macro'])\n",
    "print('Promedio Accucary k-fold:', cv_results['test_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos para undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_undertrain, X_undertest, y_undertrain, y_undertest = train_test_split(X_tomek, y_tomek, test_size=.3, random_state=1,stratify=y_tomek)\n",
    "clfU = DecisionTreeClassifier()\n",
    "clfU.fit(X_undertrain, y_undertrain)\n",
    "y_underpred = clfU.predict(X_undertest)\n",
    "print(\"Accuracy:\", accuracy_score(y_undertest, y_underpred))\n",
    "print(classification_report(y_undertest, y_underpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmU = confusion_matrix(y_undertest, y_underpred)\n",
    "\n",
    "classes = unique_labels(y_undertest, y_underpred)\n",
    "\n",
    "dfU = pd.DataFrame(cmU, index=classes, columns=classes)\n",
    "\n",
    "g = sns.heatmap(dfU, annot=True, cmap=\"Blues\")\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation=0)\n",
    "\n",
    "plt.title('Confusion matrix \\n')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "plt.autoscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "    clfU, X_tomek, y_tomek, cv=10, scoring=scoring, return_train_score=True)\n",
    "\n",
    "print('Promedio Precision:', np.mean(cv_results['test_precision_macro']))\n",
    "print('Promedio Recall:', np.mean(cv_results['test_recall_macro']))\n",
    "print('Promedio F1-score:', np.mean(cv_results['test_f1_macro']))\n",
    "print('Promedio Accucary:', np.mean(cv_results['test_accuracy']))\n",
    "\n",
    "print('Promedio Precision k-fold:', cv_results['test_precision_macro'])\n",
    "print('Promedio Recall k-fold:', cv_results['test_recall_macro'])\n",
    "print('Promedio F1-score k-fold:', cv_results['test_f1_macro'])\n",
    "print('Promedio Accucary k-fold:', cv_results['test_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 2\n",
    "Se detalla el código utilizado para el experimento que contesta la pregunta 2.\n",
    "Para esto se necesita usar clustering, y para ello se usa el método del codo para observar los clusters óptimos para trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAFICO CODO/ SILUETA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "# Cargar el DataFrame con los datos\n",
    "wd = os.path.abspath(os.path.join(os.getcwd(), os.pardir, \"db\"))\n",
    "os.chdir(wd)\n",
    "\n",
    "steam = pd.read_csv(\"steam_transformado.csv\")\n",
    "data = steam\n",
    "\n",
    "# Preprocesamiento: normalizar las características numéricas\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data[features])\n",
    "\n",
    "# Aplicar PCA para reducir la dimensionalidad de los datos\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Evaluar el número óptimo de clusters utilizando el método del codo\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "max_clusters = 10\n",
    "\n",
    "for num_clusters in range(1, max_clusters + 1):\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans.fit(data_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    if num_clusters > 1:\n",
    "        silhouette_scores.append(silhouette_score(data_scaled, kmeans.labels_))\n",
    "\n",
    "# Visualizar la variabilidad explicada por cada número de clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, max_clusters + 1), inertia, marker='o')\n",
    "plt.xlabel('Número de Clusters')\n",
    "plt.ylabel('Inertia (Suma de cuadrados dentro del cluster)')\n",
    "plt.title('Método del Codo para encontrar el número óptimo de clusters')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al no haber algo tan claro, se recurre al puntaje de silueta, que probablemente será mas util."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar el puntaje de silueta para cada número de clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(2, max_clusters + 1), silhouette_scores, marker='o')\n",
    "plt.xlabel('Número de Clusters')\n",
    "plt.ylabel('Puntaje de Silueta')\n",
    "plt.title('Puntaje de Silueta para encontrar el número óptimo de clusters')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando este gráfico se llega a la decisión de usar 4 clusters. Pues con 5, ocurre que queda un juego como único elemento de un cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters=5\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "data['cluster'] = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "# Visualizar los clusters en un gráfico 2D con PCA\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster_id in range(num_clusters):\n",
    "    cluster_mask = data['cluster'] == cluster_id\n",
    "    plt.scatter(data_pca[cluster_mask, 0], data_pca[cluster_mask, 1], label=f'Cluster {cluster_id}')\n",
    "\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.title('Clusters de juegos mediante PCA')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se muestra un gráfico PCA con los clusters elegidos y asi observar las agrupaciones de juegos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters=4\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "data['cluster'] = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "# Visualizar los clusters en un gráfico 2D con PCA\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster_id in range(num_clusters):\n",
    "    cluster_mask = data['cluster'] == cluster_id\n",
    "    plt.scatter(data_pca[cluster_mask, 0], data_pca[cluster_mask, 1], label=f'Cluster {cluster_id}')\n",
    "\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.title('Clusters de juegos mediante PCA')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se desea realizar una revision por cantidad de si no ocurre lo mismo que con 5 clusters y se grafica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento: normalizar las características numéricas\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data[features])\n",
    "\n",
    "# Definir el número de clusters que deseamos obtener\n",
    "num_clusters = 4\n",
    "\n",
    "# Aplicar K-Means para el clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "data['cluster'] = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "# Visualizar la distribución de los clusters\n",
    "cluster_counts = data['cluster'].value_counts()\n",
    "plt.bar(cluster_counts.index, cluster_counts.values, edgecolor='black')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Cantidad de juegos')\n",
    "plt.title('Distribución de juegos en cada cluster')\n",
    "plt.xticks(np.arange(num_clusters), labels=[f'Cluster {i}' for i in range(num_clusters)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se necesita analizar las medias de cada clusters en cuando a ciertas columnas para responder si cada uno de estos clusters poseen alguna tendencia en cuanto al precio de los juegos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de los clusters\n",
    "cluster_stats = data.groupby('cluster')[features].mean()\n",
    "print(cluster_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos los primeros 5 juegos de cada cluster para comparar las etiquetas y características que poseen estos juegos  y asi llegar a una relación entre estos para asi definir a cada uno. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_id in range(num_clusters):\n",
    "    print(f'\\nCluster {cluster_id}')\n",
    "    cluster_games = data[data['cluster'] == cluster_id]\n",
    "    print(cluster_games[['name', 'developer', 'publisher']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se muestra la matriz de correlación entre las características numéricas: \"english\", \"required_age\", \"achievements\", \"positive_ratings\", \"negative_ratings\", \"average_playtime\", \"median_playtime\" y \"price\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.path.abspath(os.path.join(os.getcwd(), os.pardir, \"db\"))\n",
    "os.chdir(wd)\n",
    "\n",
    "steam = pd.read_csv(\"steam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_numericas = (\"english\", \"required_age\", \"achievements\", \"positive_ratings\", \"negative_ratings\", \"average_playtime\", \"median_playtime\", \"price\")\n",
    "X = steam[list(columnas_numericas)] \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlación de Pearson de Positive ratings con respecto a las otras caracteristicas númericas\")\n",
    "correlation = X.corrwith(X['positive_ratings'], method='pearson')\n",
    "\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlación de Pearson de negative ratings con respecto a las otras caracteristicas númericas\")\n",
    "\n",
    "correlation = X.corrwith(X['negative_ratings'], method='pearson')\n",
    "\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar como en ambas matrices la mayoría de características tienen valores cercanos al 0, como la característica \"english\" que posee un valor muy cercano a 0, lo que se puede interpretar como que da lo mismo si el juego esta en ingles o no.\n",
    "\n",
    "El único valor que está cercano a 1, es el que hay entre positive y negative rating. Lo cual se puede interpretar como, por haber valoraciones de un tipo, ya sea positivas o negativas, habrán del otro. Este valor también significa que una relación positiva entre ambos valoraciones, que signi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora, tambien vamos a hacer un analisis de regresión para ver como afecta de otra manera\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Seleccionar las características (variables independientes)\n",
    "features = X.drop('positive_ratings', axis=1)\n",
    "\n",
    "# Seleccionar la variable objetivo\n",
    "target = X['positive_ratings']\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar el modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "score = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Coeficientes:\", model.coef_)\n",
    "print(\"Intercepto:\", model.intercept_)\n",
    "print(\"R^2:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las características (variables independientes)\n",
    "features = X.drop('negative_ratings', axis=1)\n",
    "\n",
    "# Seleccionar la variable objetivo\n",
    "target = X['negative_ratings']\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar el modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "score = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Coeficientes:\", model.coef_)\n",
    "print(\"Intercepto:\", model.intercept_)\n",
    "print(\"R^2:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_steam = steam.sort_values('positive_ratings', ascending=False)\n",
    "\n",
    "# Seleccionar los N juegos con más positive ratings\n",
    "N = 15  # Número de juegos a mostrar\n",
    "top_games = sorted_steam.head(N)\n",
    "\n",
    "# Crear el gráfico de barras o gráfico de puntos\n",
    "plt.figure(figsize=(10, 6))  # Tamaño del gráfico\n",
    "\n",
    "# Opción 1: Gráfico de barras\n",
    "plt.bar(top_games['name'], top_games['positive_ratings'])\n",
    "plt.xlabel('Juego')\n",
    "plt.ylabel('Positive Ratings')\n",
    "plt.title(f'Top {N} Juegos con Más Positive Ratings')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_steam = steam.sort_values('negative_ratings', ascending=False)\n",
    "\n",
    "# Seleccionar los N juegos con más positive ratings\n",
    "N = 15  # Número de juegos a mostrar\n",
    "top_games = sorted_steam.head(N)\n",
    "\n",
    "# Crear el gráfico de barras o gráfico de puntos\n",
    "plt.figure(figsize=(10, 6))  # Tamaño del gráfico\n",
    "\n",
    "# Opción 1: Gráfico de barras\n",
    "plt.bar(top_games['name'], top_games['negative_ratings'])\n",
    "plt.xlabel('Juego')\n",
    "plt.ylabel('Negative Ratings')\n",
    "plt.title(f'Top {N} Juegos con Más Negative Ratings')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 4\n",
    "Se detalla el código utilizado para el experimento que contesta la pregunta 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos una nueva columna con el porcentaje de criticas, la discretizamos y sacamos los valores NaN\n",
    "\n",
    "steam['percentage_ratings'] = steam['positive_ratings'] * 100 / (steam['positive_ratings'] + steam['negative_ratings'])\n",
    "steam['percentage_ratings'] = steam['percentage_ratings'].astype(int)\n",
    "steam = steam.dropna(subset=['percentage_ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacamos las columnas que no podemos evaluar o que son intrascendentes para un juego nuevo\n",
    "steam1 = steam.drop(['percentage_ratings', 'appid', 'name', 'developer', 'publisher', 'positive_ratings', 'negative_ratings', 'release_date', 'owners', 'average_playtime', 'median_playtime'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arbol de decision clasificador\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = steam1\n",
    "y = steam.percentage_ratings\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=23)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)   ## Entrenar usando X (features), y (clase)\n",
    "\n",
    "y_pred = clf.predict(X_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))   ## Evaluamos la predicción comparando y_test con y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la importancia de cada atributo en el árbol de decisión\n",
    "importance = clf.feature_importances_\n",
    "\n",
    "# Asociar los nombres de los atributos a su importancia\n",
    "importants = dict(zip(X.columns, importance))\n",
    "\n",
    "# Ordenar los atributos por su importancia de mayor a menor\n",
    "importants = {k: v for k, v in sorted(importants.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# Mostrar los atributos más importantes del árbol de decisión\n",
    "print(\"Los 10 atributos más importantes del árbol de decisión:\")\n",
    "for i, (atributo, importancia) in enumerate(importants.items()):\n",
    "    if i < 10:\n",
    "        print(f\"{atributo}: {importancia}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de Regresión Lineal\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "regresor_lineal = LinearRegression()\n",
    "regresor_lineal.fit(X_train, y_train)\n",
    "\n",
    "# Calcular el Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Calcular el R-squared (R2)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R2):\", r2)\n",
    "\n",
    "# Validación cruzada de Mean Squared Error (MSE)\n",
    "cv_scores = cross_val_score(regresor_lineal, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse_cv = -np.mean(cv_scores)\n",
    "print(\"Cross-Validated Mean Squared Error (MSE):\", mse_cv)\n",
    "\n",
    "# Validación cruzada de R-squared (R2)\n",
    "r2_cv_scores = cross_val_score(regresor_lineal, X, y, cv=5, scoring='r2')\n",
    "r2_cv = np.mean(r2_cv_scores)\n",
    "print(\"Cross-Validated R-squared (R2):\", r2_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de regresión Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calcular el Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Calcular el R-squared (R2)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R2):\", r2)\n",
    "\n",
    "# Validación cruzada de Mean Squared Error (MSE)\n",
    "cv_scores = cross_val_score(regressor, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse_cv = -np.mean(cv_scores)\n",
    "print(\"Cross-Validated Mean Squared Error (MSE):\", mse_cv)\n",
    "\n",
    "# Validación cruzada de R-squared (R2)\n",
    "r2_cv_scores = cross_val_score(regressor, X, y, cv=5, scoring='r2')\n",
    "r2_cv = np.mean(r2_cv_scores)\n",
    "print(\"Cross-Validated R-squared (R2):\", r2_cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
